{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "CtnHxc20lVGg"
   },
   "source": [
    "# Lab03: Data preprocessing and modeling\n",
    "\n",
    "- Full Name: Lê Nguyễn Bình Nam\n",
    "\n",
    "- Student's ID: 20127567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2nqQsadlVGm"
   },
   "source": [
    "***\n",
    "## How to do and submit assignments\n",
    "\n",
    "&#9889; You should note that I will be using a grading support program, so you need to follow the exact rules that I set, if you are not sure, please ask me, not arbitrarily follow your own will.\n",
    "\n",
    "**How to do**\n",
    "You will do it directly on this notebook file. First, enter your name and student's id in the file header above. In the file, you will complete the required in the position where be written:\n",
    "\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "When you do, you delete the line `raise NotImplementedError()`.\n",
    "\n",
    "For the parts that require code, usually right below there will be a cell (or several) containing test sets to help you know if the code is correct or not. If running this cell has no errors, it means that the test sets are passed.\n",
    "\n",
    "In some cases, the test suites may be incomplete, that is, if the test fails, the code is wrong, but if it passes the test, it is not sure correct.\n",
    "\n",
    "While doing the test, you can print to the screen, create more cells for testing. But when submitting, you delete the cells that you create, delete or comment the statements printed to the screen. Please note that <font color=red> must not delete cells or edit my code </font> (except where editing is allowed as mentioned above).\n",
    "\n",
    "While doing the test, often `Ctrl + S` to save your work, avoid loss of information.\n",
    "\n",
    "**How to submit**\n",
    "\n",
    "When grading, I will first choose `Kernel` - `Restart & Run All`, to restart and run all cells in your notebook; therefore, before submitting your lab, you should test run `Kernel` - `Restart & Run All` to make sure everything goes as expected.\n",
    "\n",
    "Then you create a submission folder with the following structure:\n",
    "- The `ID's student` folder (eg, if you have an MSSV of 1234567, name the folder `1234567`)\n",
    "     - File `1234567.ipynb` (no need to submit other files)\n",
    "\n",
    "Finally, you zip this `ID's student` folder and submit it at the link on moodle. The extension of the compressed file must be .zip (not .rar or anything else).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "vIU2_LomlVGo"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-djgfWxulVGq"
   },
   "source": [
    "Check the code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZC2XmNdKlVGr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/root/miniconda3/envs/min_ds-env/bin/python',\n",
       " '3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable, sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "ovxfxtNMlVGu"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "id": "zADGZAPMlVGu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram') # to visualize pipeline\n",
    "\n",
    "# You can also import other things ...\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "Z0JL7XEFlVGv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "bzcfEvRClVGv"
   },
   "source": [
    "## Collect data\n",
    "\n",
    "The dataset used in this lab is a pre-collected dataset for heart disease prediction. ([Reference](https://archive.ics.uci.edu/ml/datasets/heart+disease)); It is changed a few things fit the goal of the lab.\n",
    "\n",
    "Data files include:\n",
    "- File \"lab03_train.csv\": data set train\n",
    "- File \"lab03_test.csv\": data set test\n",
    "- File \"description.txt\": describe the meaning of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "cDE_MU8VlVGv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "qUIzd1oFlVGw"
   },
   "source": [
    "## Data exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "id": "sFmVedwNlVGw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     sex  cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  43.0     NaN   2       122    NaN    0        1      NaN      0      0.2   \n",
       "1  66.0  female   2       146  278.0    0        0    152.0      0      0.0   \n",
       "2  58.0    male   2       140  211.0    1        0    165.0      0      0.0   \n",
       "3  63.0  female   0       124    NaN    0        1      NaN      1      0.0   \n",
       "4  57.0    male   1       154  232.0    0        0    164.0      0      0.0   \n",
       "\n",
       "   slope  ca  thal  target  \n",
       "0    1.0   0     2       1  \n",
       "1    1.0   1     2       1  \n",
       "2    2.0   0     2       1  \n",
       "3    1.0   0     2       0  \n",
       "4    NaN   1     2       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('lab03_train.csv') \n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PKu3RUoRaSS7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 242 entries, 0 to 241\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       221 non-null    float64\n",
      " 1   sex       196 non-null    object \n",
      " 2   cp        242 non-null    int64  \n",
      " 3   trestbps  242 non-null    int64  \n",
      " 4   chol      207 non-null    float64\n",
      " 5   fbs       242 non-null    int64  \n",
      " 6   restecg   242 non-null    int64  \n",
      " 7   thalach   70 non-null     float64\n",
      " 8   exang     242 non-null    int64  \n",
      " 9   oldpeak   206 non-null    float64\n",
      " 10  slope     216 non-null    float64\n",
      " 11  ca        242 non-null    int64  \n",
      " 12  thal      242 non-null    int64  \n",
      " 13  target    242 non-null    int64  \n",
      "dtypes: float64(5), int64(8), object(1)\n",
      "memory usage: 26.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OAxtr7XlVGw"
   },
   "source": [
    "### How many rows and columns does the data have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zlZ1c7EflVGx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4Um_o5blVGx"
   },
   "source": [
    "### What does each sample mean? Does it matter that the samples have different meanings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ql5VsnYVlVGx"
   },
   "source": [
    "The data shows that each sample contains information for a patient, and it doesn't seem to matter that the samples have different meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih5D0w0WlVGy"
   },
   "source": [
    "### Does the data have duplicate sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l8gMMMlmlVGy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of duplicated lines\n",
    "data_df.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLl5KluIlVGy"
   },
   "source": [
    "### What does each column mean? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW2RYNgwlVGy"
   },
   "source": [
    "Read file \"description.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "scpKAvIRlVGz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) age:\t\tage in years\n",
      "2) sex:\t\tsex (male; female)\n",
      "3) cp: \t\tchest pain type\n",
      "4) trestbps: \tresting blood pressure\n",
      "5) chol: \tserum cholestoral in mg/dl\n",
      "6) fbs: \tfasting blood sugar > 120 mg/dl\n",
      "7) restecg: \tresting electrocardiographic results (values 0,1,2)\n",
      "8) thalach: \tmaximum heart rate achieved\n",
      "9) exang: \texercise induced angina\n",
      "10) oldpeak: \t= ST depression induced by exercise relative to rest\n",
      "11) slope: \tthe slope of the peak exercise ST segment\n",
      "12) ca: \tnumber of major vessels (0-3) colored by flourosopy\n",
      "13) thal: \tdisplays the thalassemia\n"
     ]
    }
   ],
   "source": [
    "with open('description.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7gIF118lVGz"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rOAPNhBlVG0"
   },
   "source": [
    "In the next step, you will split the data set into 2 or 3 subset. These can be train set, validation set, test set. After that, you will continue explore the train set to get its insight.\n",
    "\n",
    "The reason why not continue exploring is that the validation and testing set are the special set which must be hidden. If you explore the data too much, understand the data too much and then separate the data set, the results on the validation set and the test set may not be objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LujfMGvIlVG0"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx3A7ZIglVG0"
   },
   "source": [
    "## Make your question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riY7Pl9iXI8-"
   },
   "source": [
    "The most important step is to define what is ouput and what is input. Regarding input columns, if possible, we try to determine which columns will not be used based on the meaning of the columns and will remove these columns to simplify the next steps. For columns that are not sure whether to remove or keep, we should keep it and we will do it in the steps later.\n",
    "\n",
    "Finding this answer to this question doesn't really make much sense in practice; The main purpose of this lab is to practice preprocessing + modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "WlhcRL0YlVG1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIScaP1ZAk6W"
   },
   "source": [
    "## Data Discovery (for how to separate sets)\n",
    "To know how to split the data set, we need to explore the output column:\n",
    "\n",
    "- What data type does this column have? In the regression problem, the output column must be in numeric form; if there is no numeric form (for example, numbers but stored as strings) then we need to convert to numeric form and then separate the subsets.\n",
    "- Does this column have a missing value? If it have missing value, we will remove the rows where the output has a missing value and then split the subsets (the type of learning that learns from data where the output has a missing value is called semi-supervised); \n",
    "- If this column is categorical, what is the ratio of the classes? If the ratio of classes are disparate too much, then we may need to go back to the data collection step and collect more so that the ratio of the classes do not differ too much (or using unique techniques to solve the imbalance of the data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q2ksfSf-lVG1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What data type does output column have?\n",
    "data_df['target'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BcQnoMbxlVG1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of missing value\n",
    "data_df['target'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i758Nmi0lVG2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    54.132231\n",
       "0    45.867769\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# what is the ratio of the classes?\n",
    "data_df.target.value_counts(normalize=True).plot(kind=\"bar\", color=[\"red\", \"blue\"])\n",
    "data_df['target'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMKy7WAOZWex"
   },
   "source": [
    "OK, no problem at all. The ratio between classes is also quite balanced, so we should be able to apply common techniques to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgcvfyEPlVG2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQXS782plVG3",
    "tags": []
   },
   "source": [
    "## Preprocessing (Splitting Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enag7q74Ztvo"
   },
   "source": [
    "Now we will perform the preprocessing step which is to split the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "id": "GOxpBQ2hlVG3"
   },
   "outputs": [],
   "source": [
    "# Get predictor(X) and target(y)\n",
    "y_sr = data_df[\"target\"] \n",
    "X_df = data_df.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "id": "tBKNBvtPlVG3"
   },
   "outputs": [],
   "source": [
    "# Split the training set and the validation set by the ratio of 80%: 20%\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = \\\n",
    "                              train_test_split(X_df, y_sr, \n",
    "                                               test_size=0.2, \n",
    "                                               stratify=y_sr, \n",
    "                                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rxUbZC8IlVG3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y6QO5DEwlVG4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tMzu6_kIlVG4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "as6Tz8telVG4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false",
    "id": "mEJirtzJlVG4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([214, 160, 23, 57, 206], dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzBMaA4JatSF"
   },
   "source": [
    "&#9889; I've fixed `random_state` in `train_test_split` to make sure my results are the same as yours. However, I don't know if this is guaranteed with different operating systems. The result of my `train_X_df.head().index` statement is 5 values: 214, 160, 23, 57, 206. If yours is different, please report back to me on moodle (or zalo), because if it is different, your results will also be different from mine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "b9EXZJOalVG5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "83Q7v7BYlVG5"
   },
   "source": [
    "## Exploring data on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEM0lFBHlVG5"
   },
   "source": [
    "After separating the subsets, we can freely explore on the training set without scaring about data leakage problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY1HXxl3lVG5"
   },
   "source": [
    "### Check data type of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fGmgPdoulVG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         float64\n",
       "sex          object\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol        float64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach     float64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope       float64\n",
       "ca            int64\n",
       "thal          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtmDTZWUlVG6"
   },
   "source": [
    "### Exploring the distribution of numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "04n9XUeIlVG6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         float64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol        float64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach     float64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope       float64\n",
       "ca            int64\n",
       "thal          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.dtypes[train_X_df.dtypes != object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UBpuFrXrcoVE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>174.00</td>\n",
       "      <td>193.00</td>\n",
       "      <td>193.00</td>\n",
       "      <td>164.00</td>\n",
       "      <td>193.00</td>\n",
       "      <td>193.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>193.00</td>\n",
       "      <td>164.00</td>\n",
       "      <td>171.00</td>\n",
       "      <td>193.00</td>\n",
       "      <td>193.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.18</td>\n",
       "      <td>1.15</td>\n",
       "      <td>131.85</td>\n",
       "      <td>245.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.55</td>\n",
       "      <td>147.04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.08</td>\n",
       "      <td>1.64</td>\n",
       "      <td>16.51</td>\n",
       "      <td>50.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.54</td>\n",
       "      <td>23.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>131.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>211.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>131.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>239.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>152.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>140.00</td>\n",
       "      <td>275.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>162.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>417.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>182.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age     cp  trestbps   chol    fbs  restecg  thalach  exang  oldpeak  \\\n",
       "count 174.00 193.00    193.00 164.00 193.00   193.00    55.00 193.00   164.00   \n",
       "mean   55.18   1.15    131.85 245.91   0.14     0.55   147.04   0.31     1.06   \n",
       "std     9.08   1.64     16.51  50.38   0.35     0.54    23.36   0.46     1.22   \n",
       "min    29.00   0.00    100.00 131.00   0.00     0.00    71.00   0.00     0.00   \n",
       "25%    48.00   0.00    120.00 211.75   0.00     0.00   131.50   0.00     0.00   \n",
       "50%    57.00   1.00    130.00 239.00   0.00     1.00   152.00   0.00     0.70   \n",
       "75%    62.00   2.00    140.00 275.25   0.00     1.00   162.50   1.00     1.80   \n",
       "max    76.00   9.00    180.00 417.00   1.00     2.00   182.00   1.00     6.20   \n",
       "\n",
       "       slope     ca   thal  \n",
       "count 171.00 193.00 193.00  \n",
       "mean    1.45   0.70   2.31  \n",
       "std     0.61   1.00   0.62  \n",
       "min     0.00   0.00   0.00  \n",
       "25%     1.00   0.00   2.00  \n",
       "50%     2.00   0.00   2.00  \n",
       "75%     2.00   1.00   3.00  \n",
       "max     2.00   4.00   3.00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.float\", \"{:.2f}\".format)\n",
    "train_X_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "L12O7thLlVG8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbGOiPEglVG8"
   },
   "source": [
    "## Preprocessing (Training set) (3.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will add and remove some columns as follows:\n",
    "- With the `cp` column, we will proceed to extract the corresponding `cp_reduced` column. When you explore, you will see that `cp` has quite a few different values in the train set (in the train set have 10 values, but in the test set have more), some of which only appear one or very few times; if we don't deal with it, when converting to numeric by one-hot method, there will be many columns &#8594; prone to overfit. We will handle this problem as follows: take only `num_top_cp_values` (for example, 4) the value that appear most often, the rest will be replaced by the value `-1` (When modeling, We will encode this column as one-hot, so choose any value that is not in `top_cp_values` to replace it, but we will choose the value `-1`). Later, we will experiment to choose the right `num_top_cp_values` value. After processing the `cp_reduced` column, we add this column to the dataframe and remove the `cp` column.\n",
    "- Removed the `thalach` column because it has too many missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `ColAdderDropper` will perform the steps above. Because in the steps above, there is a step where we need to compute the values from the training set (`num_top_cp_values` the value of the column \"cp_reduced\" that appear most) and use these values to \"transform\" the dataset. (it can be a training set, it can be a validation set or a test set) so we have to define a class in Sklearn's \"transformer\" form (so we can use Sklearn's pipeline later) and in it we have to manually define it. define `fit` and `transform` methods (also if you just need to \"transform\" the data set without calculating any values from the training set, using `FunctionTransformer` as in the file [\"08-Demo.ipynb\"](https://colab.research.google.com/drive/1kZwBNAikKWplKTCKIn0ofQ9eIX12ePEl#scrollTo=gn0O90j_prDS) will more convenient). Note: the `fit` method is only used on the training set, and the `transform` method (after `fit`) can be used for any set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have pre-installed the `fit` method; after `fit`, the values of the `cp` column along with the number of occurrences will be stored in the `self.cp_counts_` attribute (when \"transform\" this information is not needed, but you may want to see this information), and `num_top_cp_values` the value that occurs most often is saved to `self.top_cp_values_` (`num_top_cp_values` is the hyperparameter that must be specified when creating an object of this class). Your task is to implement the `transform` method (in which `self.top_cp_values_` will be used); Please note that the data in `X_df` is not changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as you can see below, the `ColAdderDropper` class is inherited from two Sklearn classes `BaseEstimator` and `TransformerMixin`. This inheritance helps our class automatically have methods like `set_params`, `get_params`, `fit_transform` (otherwise we would have to define these methods ourselves). If you want to learn more about how to write classes in Sklearn format, you can read [here](https://scikit-learn.org/stable/developers/develop.html?highlight=baseestimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "v5VbKC_ilVG8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bbd42fec4a1b01ae8a8a58dc28e06d2",
     "grade": false,
     "grade_id": "cell-c2cb62acb65582f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_cp_values=3):\n",
    "        self.num_top_cp_values = num_top_cp_values\n",
    "        \n",
    "    def fit(self, X_df, y=None):\n",
    "        self.cp_counts_ = X_df['cp'].value_counts()\n",
    "        cps = list(self.cp_counts_.index)\n",
    "        self.top_cp_values_ = cps[:max(1, min(self.num_top_cp_values, len(cps)))]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        \n",
    "        out_df = X_df.copy()\n",
    "        # YOUR CODE HERE\n",
    "        out_df['cp_reduced'] = np.where(np.isin(out_df['cp'], self.top_cp_values_), out_df['cp'], -1)\n",
    "        out_df = out_df.drop(columns=['cp', 'thalach'])\n",
    "\n",
    "        out_df = out_df.sort_index(axis=1)\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-CYn5spSlVG9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    117\n",
      "2     69\n",
      "1     36\n",
      "3      5\n",
      "6      4\n",
      "9      3\n",
      "4      3\n",
      "7      2\n",
      "5      2\n",
      "8      1\n",
      "Name: cp, dtype: int64\n",
      "\n",
      "[0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# TEST FIT METHOD\n",
    "col_adderdropper = ColAdderDropper(num_top_cp_values=3)\n",
    "col_adderdropper.fit(data_df)\n",
    "print(col_adderdropper.cp_counts_)\n",
    "print()\n",
    "print(col_adderdropper.top_cp_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "id": "ujHTyrGJlVG9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "258f156033739a9ad92fb68786c9f38b",
     "grade": true,
     "grade_id": "cell-7a54f3df0d0a2556",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ca</th>\n",
       "      <th>chol</th>\n",
       "      <th>cp_reduced</th>\n",
       "      <th>exang</th>\n",
       "      <th>fbs</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>restecg</th>\n",
       "      <th>sex</th>\n",
       "      <th>slope</th>\n",
       "      <th>thal</th>\n",
       "      <th>trestbps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>64.00</td>\n",
       "      <td>0</td>\n",
       "      <td>335.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>49.00</td>\n",
       "      <td>0</td>\n",
       "      <td>271.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "      <td>239.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>177.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  ca   chol  cp_reduced  exang  fbs  oldpeak  restecg     sex  slope  \\\n",
       "214 64.00   0 335.00           2      0    0     0.00        1     NaN   2.00   \n",
       "160 49.00   0 271.00           1      0    0     0.00        1  female    NaN   \n",
       "23  59.00   1 239.00           0      1    0      NaN        0    male   1.00   \n",
       "57  60.00   0    NaN           2      0    1     0.00        1  female   2.00   \n",
       "206 65.00   0 177.00           0      0    0     0.40        1    male   2.00   \n",
       "\n",
       "     thal  trestbps  \n",
       "214     2       140  \n",
       "160     2       134  \n",
       "23      3       110  \n",
       "57      2       120  \n",
       "206     3       120  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST TRANSFORM METHOD\n",
    "fewer_cols_train_X_df = col_adderdropper.transform(train_X_df)\n",
    "assert set(fewer_cols_train_X_df.columns) == \\\n",
    "                                {'age', 'ca', 'chol', 'cp_reduced', 'exang', 'fbs', 'oldpeak', 'restecg', 'sex', 'slope', 'thal', 'trestbps'}\n",
    "                                \n",
    "assert np.all(fewer_cols_train_X_df['cp_reduced'].value_counts() == \\\n",
    "              pd.Series([94, 55, 29, 15], \n",
    "                        [0, 2, 1, -1]))\n",
    "fewer_cols_train_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will have to make a list of numeric columns (numerical) and non-numeric columns (categorical). The next preprocessing steps are as follows:\n",
    "- For numeric columns, we will fill in the missing value with the mean value of the column <font color=gray> (hint: use `SimpleImputer` in Sklearn)</font>. For *all* numeric columns in the training set, we all need to compute the mean, because we don't know which columns will be missing values when predicting with the new input vectors.\n",
    "- For non-numeric and unordered columns:\n",
    "     - We will fill in the missing value with the mode value (the most occurring value) of the column <font color=gray> (hint: use `SimpleImputer` in Sklearn)</font>. With *all* non-numerical and unordered columns, we all need to compute the mode, because we don't know which columns will be missing values when predicting with the new input vectors.\n",
    "     - Then we will convert to numeric by one-hot encoding method <font color=gray> (hint: use `OneHotEncoder` in Sklearn, watch out for `handle_unknown` parameter because when predicting with vectors- new input string ...)</font>.\n",
    "\n",
    "- Finally, when all columns have been filled with missing values and are in numeric form, we will proceed to normalize the range by subtracting the mean and dividing by the column's std to help the optimization algorithm as Gradient Descent, LBFGS, ... converge faster than <font color=gray>(hint: use `StandardScaler` in Sklearn)</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to create a pipeline, name it `preprocess_pipeline`, including: the step of adding `cp_reduced` columns and removing columns (installed in class `ColAdderDropper`, you set `num_top_cp_values=3`), and all the steps here (please note to follow the order of the steps and columns that I have described). Once you've created this pipeline, you'll call the `fit_transform` method with `train_X_df` as input to compute the values from the training set (for example, `top_cp_values_` in adding and removing columns; mean and mode in the missing value processing step; mean and std in the normalization step) and also `train_X_df` preprocessing; The result will be `train_X_df` after preprocessing, which is a Numpy array, you name it `preprocessed_train_X`. <font color=gray>(Hint: you read how to use pipeline in [document](https://scikit-learn.org/stable/modules/compose.html#transforming-target-in-regression), maybe skip 6.1.2; you'll need to use `Pipeline`/`make_pipeline` and `ColumnTransformer`/`make_column_transformer`.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "As9Dp0wZlVG-",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7a1d4ae5e4fa50b60b4998de6be96a1",
     "grade": false,
     "grade_id": "cell-ae75d7dfa7256c7f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# You determine which column is numerical or categorical\n",
    "# (Hint: consider columns with different number of values < 15 )\n",
    "# YOUR CODE HERE\n",
    "categorical_cols = []\n",
    "numerics_cols = []\n",
    "cols_name = ['age', 'ca', 'chol', 'cp_reduced', 'exang', 'fbs', 'oldpeak', 'restecg', 'sex', 'slope', 'thal', 'trestbps']\n",
    "for name in cols_name:\n",
    "    if len(set(fewer_cols_train_X_df[name].dropna())) < 15:\n",
    "        categorical_cols.append(name)\n",
    "    else:\n",
    "        numerics_cols.append(name)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"fill_mean\", SimpleImputer(strategy=\"mean\"))]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"fill_mode\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "           (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor_transform = ColumnTransformer(\n",
    "    transformers=[(\"numeric\", numeric_transformer, numerics_cols),\n",
    "        (\"categorical\", categorical_transformer, categorical_cols),]\n",
    ")\n",
    "\n",
    "#preprocess_pipeline\n",
    "preprocess_pipeline = Pipeline(\n",
    "    steps=[(\"adddrop\", ColAdderDropper(num_top_cp_values = 3)),\n",
    "           (\"transform\", preprocessor_transform), \n",
    "           (\"scaler\", StandardScaler())]\n",
    ")\n",
    "# fit_transform\n",
    "preprocessed_train_X = preprocess_pipeline.fit_transform(train_X_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "id": "sJKDf9IqlVG_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34cd22a6a9f34822f20f8d3c89115986",
     "grade": true,
     "grade_id": "cell-1cf65ae2cdb14c0c",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;adddrop&#x27;, ColAdderDropper()),\n",
       "                (&#x27;transform&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;trestbps&#x27;]),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;,\n",
       "                                                   &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;thal&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;adddrop&#x27;, ColAdderDropper()),\n",
       "                (&#x27;transform&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;trestbps&#x27;]),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;,\n",
       "                                                   &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;thal&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColAdderDropper</label><div class=\"sk-toggleable__content\"><pre>ColAdderDropper()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transform: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                  SimpleImputer())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;trestbps&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;,\n",
       "                                  &#x27;sex&#x27;, &#x27;slope&#x27;, &#x27;thal&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;trestbps&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;, &#x27;slope&#x27;, &#x27;thal&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('adddrop', ColAdderDropper()),\n",
       "                ('transform',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('fill_mean',\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  ['age', 'chol', 'oldpeak',\n",
       "                                                   'trestbps']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('fill_mode',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['ca', 'cp_reduced', 'exang',\n",
       "                                                   'fbs', 'restecg', 'sex',\n",
       "                                                   'slope', 'thal'])])),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "assert preprocessed_train_X.shape == (193, 29)\n",
    "row0 = [1.026, 1.924, -0.953, 0.495, 0.832, -0.503, -0.386, -0.269, -0.102, -0.29, -0.974, -0.421, 1.584, 0.672, -0.672,\n",
    "        0.403, -0.403, -0.935, 0.974, -0.145, -0.647, 0.647, -0.234, -0.789, 0.878, -0.072, -0.269, 0.915, -0.789]\n",
    "assert list(preprocessed_train_X[0].round(3)) == row0\n",
    "preprocess_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "1b07tI86lVG_"
   },
   "source": [
    "## Preprocessing (validation set) (1.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once we have `preprocess_pipeline` with statistics calculated from the training set, we can easily use the `transform` method to preprocess the new input vectors in the validation and test sets. . Below, you will do the same to preprocess `val_X_df` and save the result in `preprocessed_val_X` (only need 1 line of code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "3VVrWVhPlVG_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "986f547abfe534258eb2c41f692c1084",
     "grade": false,
     "grade_id": "cell-5b00ff693785976e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "preprocessed_val_X = preprocess_pipeline.transform(val_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "id": "un38UlKolVG_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11d78d3e447c4f152ba6106fa18ad60f",
     "grade": true,
     "grade_id": "cell-b9c978682fecdf3c",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert preprocessed_val_X.shape == (49, 29)\n",
    "row0 = [-1.534, -0.797, -0.953, -0.72, 0.832, -0.503, -0.386, -0.269, -0.102, -0.29, -0.974, -0.421, 1.584, 0.672, -0.672,\n",
    "        0.403, -0.403, -0.935, 0.974, -0.145, 1.545, -1.545, -0.234, 1.268, -1.139, -0.072, -0.269, 0.915, -0.789]\n",
    "assert list(preprocessed_val_X[0].round(3)) == row0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why you should not do the following 2 ways:\n",
    "- Preprocess the validation set with statistical values (mean, mode, ...) calculated from the validation set\n",
    "- Or preprocess all the data and then split the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "rda_-rndlVHA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a1567a9361126ee5dd2d6371498efda",
     "grade": true,
     "grade_id": "cell-c9f9e4ac63684628",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because if we fill mean and mode into the empty values of the validation set (method 1) or fill mean and mode before separating into training set and validation set (method 2), the algorithm will partially learn (or entire) validation set, which leads to a loss of objectivity when using the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "esCTOTmclVHA"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "a6BCMtZElVHA"
   },
   "source": [
    "## Preprocessing and Modeling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfvgdyEilVHB"
   },
   "source": [
    "### Find the best model (4đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the MLP model for classification. You will create an end-to-end pipeline consisting of: the above preprocessing steps + MLP (with the hyperparameters `hidden_layer_sizes=(50), activation='relu', solver='lbfgs', random_state=0 , max_iter=10000`). You name this pipeline `full_pipeline`. Creating an end-to-end pipeline like this has the following benefits:\n",
    "- Helps simplify:\n",
    "     - For end-to-end training, simply call the `fit` method of this pipeline on the raw training set. Now the \"transformers\" in the preprocessing steps will call `fit_transform`, and the \"classifiers\" at the end will call `fit`.\n",
    "     - With input vectors in raw form, to predict just call the pipeline's `predict` method. At this point, the \"transformers\" in the preprocessing steps will call `transform`, and the \"classifiers\" at the end will call `predict`.\n",
    "- Helps avoid preprocessing the validation/test-set in the wrong way (as mentioned in the \"Preprocessing (validation set)\" section above). \n",
    "- Makes it easy to simultaneously test the values of hyperparameters at each step in the pipeline (will do below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've got this end-to-end pipeline, you'll experiment:\n",
    "- Hyperparameter `alpha` (L2 regularization coefficient) of `MLPClassifier` with 5 different values: from 0 to 100.\n",
    "- Hyperparameter `num_top_cp_values` of `ColAdderDropper` (at preprocessing step) with 5 different values: 1, 3, 5, 7, 9.\n",
    "\n",
    "To reassign `alpha` and `num_top_cp_values` to `full_pipeline`, you would use the `set_params` method:\n",
    "\n",
    "`full_pipeline.set_params(mlpclassifier__alpha=...)`\n",
    "\n",
    "If you create a pipeline with `make_pipeline` then the names of the steps will be automatically taken as the names of the classes and lowercase like the two names above. If you use `Pipeline` and name the steps yourself, use your name in the `set_params` method.\n",
    "\n",
    "Thus, for each model you will: train on the training set, calculate the metric here as the accuracy on the training set and the validation set, and then `append` the measure into two corresponding lists:`train_accs` and `val_accs` (for clarity, you calculate the accuracy in %, meaning it has a value from 0-100, not 0-1). You save the highest accuracy on the validation set and the `alpha` and `num_top_cp_values` values respectively into the `best_val_acc`, `best_alpha`, `best_num_top_cp_values` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "8axdeNeslVHB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0662cf28420d8aab58040eaa80f76ed2",
     "grade": false,
     "grade_id": "cell-fdd12a79fb590313",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating full_pipeline\n",
    "# YOUR CODE HERE\n",
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(50), \n",
    "    activation='relu', \n",
    "    solver='lbfgs', \n",
    "    random_state=0, \n",
    "    max_iter=10000\n",
    ")\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[(\"preprocesspipeline\", preprocess_pipeline),\n",
    "           (\"mlpclassifier\", mlp_classifier)]\n",
    ")\n",
    "\n",
    "# Experiment with different values of hyperparameters (the whole process can take 2-3 minutes) and choose the best values\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "alphas = [0,0.01,0.1, 1, 10, 100]\n",
    "num_top_cp_values_s = [1, 3, 5, 7,9]\n",
    "best_val_acc = 0\n",
    "best_alpha = None\n",
    "best_num_top_cp_values = None\n",
    "for alpha in alphas:\n",
    "    for num_top_cp_values in num_top_cp_values_s:\n",
    "        # YOUR CODE HERE\n",
    "        full_pipeline.set_params(mlpclassifier__alpha = alpha)\n",
    "        full_pipeline.set_params(preprocesspipeline__adddrop__num_top_cp_values = num_top_cp_values)\n",
    "\n",
    "        full_pipeline.fit(train_X_df, train_y_sr)\n",
    "        train_acc = full_pipeline.score(train_X_df, train_y_sr) * 100\n",
    "        val_acc = full_pipeline.score(val_X_df, val_y_sr) * 100\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_alpha = alpha\n",
    "            best_num_top_cp_values = num_top_cp_values       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BAzogpDulVHC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocesspipeline&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;adddrop&#x27;,\n",
       "                                  ColAdderDropper(num_top_cp_values=9)),\n",
       "                                 (&#x27;transform&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                                    SimpleImputer())]),\n",
       "                                                                   [&#x27;age&#x27;,\n",
       "                                                                    &#x27;chol&#x27;,\n",
       "                                                                    &#x27;oldpeak&#x27;,\n",
       "                                                                    &#x27;trestbps&#x27;]),\n",
       "                                                                  (&#x27;categorical&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                                    SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                   (&#x27;onehot&#x27;,\n",
       "                                                                                    OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                   [&#x27;ca&#x27;,\n",
       "                                                                    &#x27;cp_reduced&#x27;,\n",
       "                                                                    &#x27;exang&#x27;,\n",
       "                                                                    &#x27;fbs&#x27;,\n",
       "                                                                    &#x27;restecg&#x27;,\n",
       "                                                                    &#x27;sex&#x27;,\n",
       "                                                                    &#x27;slope&#x27;,\n",
       "                                                                    &#x27;thal&#x27;])])),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;mlpclassifier&#x27;,\n",
       "                 MLPClassifier(alpha=100, hidden_layer_sizes=50, max_iter=10000,\n",
       "                               random_state=0, solver=&#x27;lbfgs&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocesspipeline&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;adddrop&#x27;,\n",
       "                                  ColAdderDropper(num_top_cp_values=9)),\n",
       "                                 (&#x27;transform&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                                    SimpleImputer())]),\n",
       "                                                                   [&#x27;age&#x27;,\n",
       "                                                                    &#x27;chol&#x27;,\n",
       "                                                                    &#x27;oldpeak&#x27;,\n",
       "                                                                    &#x27;trestbps&#x27;]),\n",
       "                                                                  (&#x27;categorical&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                                    SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                   (&#x27;onehot&#x27;,\n",
       "                                                                                    OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                   [&#x27;ca&#x27;,\n",
       "                                                                    &#x27;cp_reduced&#x27;,\n",
       "                                                                    &#x27;exang&#x27;,\n",
       "                                                                    &#x27;fbs&#x27;,\n",
       "                                                                    &#x27;restecg&#x27;,\n",
       "                                                                    &#x27;sex&#x27;,\n",
       "                                                                    &#x27;slope&#x27;,\n",
       "                                                                    &#x27;thal&#x27;])])),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;mlpclassifier&#x27;,\n",
       "                 MLPClassifier(alpha=100, hidden_layer_sizes=50, max_iter=10000,\n",
       "                               random_state=0, solver=&#x27;lbfgs&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocesspipeline: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;adddrop&#x27;, ColAdderDropper(num_top_cp_values=9)),\n",
       "                (&#x27;transform&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;trestbps&#x27;]),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;,\n",
       "                                                   &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;thal&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColAdderDropper</label><div class=\"sk-toggleable__content\"><pre>ColAdderDropper(num_top_cp_values=9)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transform: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                  SimpleImputer())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;trestbps&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;,\n",
       "                                  &#x27;sex&#x27;, &#x27;slope&#x27;, &#x27;thal&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;trestbps&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;, &#x27;slope&#x27;, &#x27;thal&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=100, hidden_layer_sizes=50, max_iter=10000, random_state=0,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocesspipeline',\n",
       "                 Pipeline(steps=[('adddrop',\n",
       "                                  ColAdderDropper(num_top_cp_values=9)),\n",
       "                                 ('transform',\n",
       "                                  ColumnTransformer(transformers=[('numeric',\n",
       "                                                                   Pipeline(steps=[('fill_mean',\n",
       "                                                                                    SimpleImputer())]),\n",
       "                                                                   ['age',\n",
       "                                                                    'chol',\n",
       "                                                                    'oldpeak',\n",
       "                                                                    'trestbps']),\n",
       "                                                                  ('categorical',\n",
       "                                                                   Pipeline(steps=[('fill_mode',\n",
       "                                                                                    SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                   ('onehot',\n",
       "                                                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                   ['ca',\n",
       "                                                                    'cp_reduced',\n",
       "                                                                    'exang',\n",
       "                                                                    'fbs',\n",
       "                                                                    'restecg',\n",
       "                                                                    'sex',\n",
       "                                                                    'slope',\n",
       "                                                                    'thal'])])),\n",
       "                                 ('scaler', StandardScaler())])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=100, hidden_layer_sizes=50, max_iter=10000,\n",
       "                               random_state=0, solver='lbfgs'))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XoKMAgEulVHC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f33688c1c8f4b1a71567209f5872b5e7",
     "grade": true,
     "grade_id": "cell-0b98eab69b5f1ff7",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert round(best_val_acc, 2) == 85.71\n",
    "assert best_alpha == 1\n",
    "assert best_num_top_cp_values == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "IFTBKkW5lVHC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the result\n",
    "train_accs_df = pd.DataFrame(data=np.array(train_accs).reshape(len(alphas), -1),\n",
    "                             index=alphas, columns=num_top_cp_values_s)\n",
    "val_accs_df = pd.DataFrame(\n",
    "    data=np.array(val_accs).reshape(len(alphas), -1), \n",
    "    index=alphas, columns=num_top_cp_values_s)\n",
    "min_err = min(min(train_accs), min(val_accs))\n",
    "max_err = max(max(train_accs), max(val_accs))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_accs_df, vmin=min_err, vmax=max_err, square=True, \n",
    "            annot=True, cbar=False, fmt='.2f', cmap='Reds')\n",
    "plt.title('train accuracies'); plt.xlabel('num_top_cp_values'); plt.ylabel('alpha')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(val_accs_df, vmin=min_err, vmax=max_err, square=True, \n",
    "            annot=True, cbar=False, fmt='.2f', cmap='Reds')\n",
    "plt.title('validation accuracies'); plt.xlabel('num_top_cp_values'); plt.ylabel('alpha');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the impact of the hyperparameter `alpha` (whatever you say, if you don't know, say you don't know):\n",
    "- How do you expect when `alpha` changes, how will the accuracy on the training set and validation set change? Why do you expect so?\n",
    "- Are the above results the same as your expectation? If not, why do you think that's the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "rrIpJ6D6lVHC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e0471605e1a0872e36754fa0f485aa1",
     "grade": true,
     "grade_id": "cell-4debcfe69b8e605b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training set: As the alpha parameter increases, the accuracy decreases\n",
    "* Expectation: As the alpha parameter increases, the accuracy decreases in the validation set\n",
    "* Reality: On the contrary, increasing the alpha parameter increases the accuracy (in general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the impact of the `num_top_cp_values` hyperparameter (whatever you say, where you don't know, say you don't know):\n",
    "- How do you expect when `num_top_cp_values` changes, how will the accuracy on the training set and validation set change? Why do you expect so?\n",
    "- Are the above results the same as your expectation? If not, why do you think that's the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "TSylFa2NlVHD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49982bae0349935c9ca94046bf830735",
     "grade": true,
     "grade_id": "cell-94737f293bd3c2a8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `num_top_cp_values` parameter doesn't seem to affect accuracy much, but it is quite small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you will retrain `full_pipeline` on `X_df` and `y_sr` (training set + validation set) with `best_alpha` and `best_num_top_cp_values` found above to get the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "id": "_H4FSj9FlVHD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e771c0641435719860146ab39be71ef8",
     "grade": true,
     "grade_id": "cell-34157b0f98b9d3f5",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocesspipeline&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;adddrop&#x27;, ColAdderDropper()),\n",
       "                                 (&#x27;transform&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                                    SimpleImputer())]),\n",
       "                                                                   [&#x27;age&#x27;,\n",
       "                                                                    &#x27;chol&#x27;,\n",
       "                                                                    &#x27;oldpeak&#x27;,\n",
       "                                                                    &#x27;trestbps&#x27;]),\n",
       "                                                                  (&#x27;categorical&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                                    SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                   (&#x27;onehot&#x27;,\n",
       "                                                                                    OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                   [&#x27;ca&#x27;,\n",
       "                                                                    &#x27;cp_reduced&#x27;,\n",
       "                                                                    &#x27;exang&#x27;,\n",
       "                                                                    &#x27;fbs&#x27;,\n",
       "                                                                    &#x27;restecg&#x27;,\n",
       "                                                                    &#x27;sex&#x27;,\n",
       "                                                                    &#x27;slope&#x27;,\n",
       "                                                                    &#x27;thal&#x27;])])),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;mlpclassifier&#x27;,\n",
       "                 MLPClassifier(alpha=1, hidden_layer_sizes=50, max_iter=10000,\n",
       "                               random_state=0, solver=&#x27;lbfgs&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocesspipeline&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;adddrop&#x27;, ColAdderDropper()),\n",
       "                                 (&#x27;transform&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                                    SimpleImputer())]),\n",
       "                                                                   [&#x27;age&#x27;,\n",
       "                                                                    &#x27;chol&#x27;,\n",
       "                                                                    &#x27;oldpeak&#x27;,\n",
       "                                                                    &#x27;trestbps&#x27;]),\n",
       "                                                                  (&#x27;categorical&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                                    SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                   (&#x27;onehot&#x27;,\n",
       "                                                                                    OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                   [&#x27;ca&#x27;,\n",
       "                                                                    &#x27;cp_reduced&#x27;,\n",
       "                                                                    &#x27;exang&#x27;,\n",
       "                                                                    &#x27;fbs&#x27;,\n",
       "                                                                    &#x27;restecg&#x27;,\n",
       "                                                                    &#x27;sex&#x27;,\n",
       "                                                                    &#x27;slope&#x27;,\n",
       "                                                                    &#x27;thal&#x27;])])),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;mlpclassifier&#x27;,\n",
       "                 MLPClassifier(alpha=1, hidden_layer_sizes=50, max_iter=10000,\n",
       "                               random_state=0, solver=&#x27;lbfgs&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocesspipeline: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;adddrop&#x27;, ColAdderDropper()),\n",
       "                (&#x27;transform&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;trestbps&#x27;]),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;,\n",
       "                                                   &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;thal&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColAdderDropper</label><div class=\"sk-toggleable__content\"><pre>ColAdderDropper()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transform: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numeric&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;fill_mean&#x27;,\n",
       "                                                  SimpleImputer())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;trestbps&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;fill_mode&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;,\n",
       "                                  &#x27;sex&#x27;, &#x27;slope&#x27;, &#x27;thal&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;trestbps&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ca&#x27;, &#x27;cp_reduced&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;, &#x27;slope&#x27;, &#x27;thal&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1, hidden_layer_sizes=50, max_iter=10000, random_state=0,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocesspipeline',\n",
       "                 Pipeline(steps=[('adddrop', ColAdderDropper()),\n",
       "                                 ('transform',\n",
       "                                  ColumnTransformer(transformers=[('numeric',\n",
       "                                                                   Pipeline(steps=[('fill_mean',\n",
       "                                                                                    SimpleImputer())]),\n",
       "                                                                   ['age',\n",
       "                                                                    'chol',\n",
       "                                                                    'oldpeak',\n",
       "                                                                    'trestbps']),\n",
       "                                                                  ('categorical',\n",
       "                                                                   Pipeline(steps=[('fill_mode',\n",
       "                                                                                    SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                   ('onehot',\n",
       "                                                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                   ['ca',\n",
       "                                                                    'cp_reduced',\n",
       "                                                                    'exang',\n",
       "                                                                    'fbs',\n",
       "                                                                    'restecg',\n",
       "                                                                    'sex',\n",
       "                                                                    'slope',\n",
       "                                                                    'thal'])])),\n",
       "                                 ('scaler', StandardScaler())])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=1, hidden_layer_sizes=50, max_iter=10000,\n",
       "                               random_state=0, solver='lbfgs'))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "full_pipeline.set_params(mlpclassifier__alpha = best_alpha)\n",
    "full_pipeline.set_params(preprocesspipeline__adddrop__num_top_cp_values = best_num_top_cp_values)\n",
    "\n",
    "full_pipeline.fit(X_df, y_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "s7un-crLlVHD"
   },
   "source": [
    "### Evaluate your model(1đ)\n",
    "\n",
    "You will use the final model above to make predictions with the inputs in the test set (file \"lab03_test.csv\"). In order for me to be able to score (compare with the hidden groundtruth) you have to create a csv file with a single `target` column which is your predicted value (1 - has disease, and 0 - no). You name your file `my_preds.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5jk7q3AaygtG"
   },
   "outputs": [],
   "source": [
    "test_X_df = pd.read_csv(\"lab03_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "W6lbh5jeywFl"
   },
   "outputs": [],
   "source": [
    "test_X_df.to_csv(\"lab03_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "YXC5LEqNlVHE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "226b0f0ebb7e79c2866d02164cec9e2d",
     "grade": false,
     "grade_id": "cell-e184d7a3003ba334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "pred = full_pipeline.predict(test_X_df)\n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df['target']=pd.Series(pred)\n",
    "\n",
    "pred_df.to_csv(\"my_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1d6trk_elVHE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1ff8fb8e8c561377393942df69da26c",
     "grade": true,
     "grade_id": "cell-dbdc218117501513",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "my_preds_df = pd.read_csv('my_preds.csv')\n",
    "assert round(my_preds_df['target'].mean(), 3) == 0.574\n",
    "assert np.all(my_preds_df.iloc[:5].values.reshape(-1) == \\\n",
    "                                     np.array([0, 0, 1, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oy9yh-uEiiXr"
   },
   "source": [
    "### Experiment with other classification models (Bonus, maximum 2pts).\n",
    "\n",
    "In this section, you can try other classification models with the MLP above to optimize the accuracy on the validation (or test) set as possible.\n",
    "\n",
    "You can try on a subset of features to find the most optimal set of features. Or You can also try **fine turning** the hyperparameters of the above MLP model to find a more optimal set of parameters (such as `hidden_layer`, `activation`, `solver`, `learning_rate' `). The higher the result on your test set, the more points you will get💪💪💪\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 14:47:42.133900: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lab03_train.csv')\n",
    "y = data['target']\n",
    "x = data.drop(\"target\", axis=1)\n",
    "name_col = ['age','ca','chol','cp_reduced','exang','fbs','oldpeak','restecg','sex','slope' ,'thal' ,'trestbps']\n",
    "\n",
    "col_adderdropper = ColAdderDropper(num_top_cp_values=3)\n",
    "col_adderdropper.fit(x)\n",
    "\n",
    "x = col_adderdropper.transform(x)\n",
    "for name in name_col:\n",
    "    if len(set(x[name].dropna())) < 15:\n",
    "        x[name].fillna(x[name].mode()[0], inplace=True)\n",
    "    else:\n",
    "        x[name].fillna((x[name].mean()), inplace=True)\n",
    "x['sex'] = x['sex'].replace(['female','male'],[0,1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ca</th>\n",
       "      <th>chol</th>\n",
       "      <th>cp_reduced</th>\n",
       "      <th>exang</th>\n",
       "      <th>fbs</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>restecg</th>\n",
       "      <th>sex</th>\n",
       "      <th>slope</th>\n",
       "      <th>thal</th>\n",
       "      <th>trestbps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>41.00</td>\n",
       "      <td>0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>69.00</td>\n",
       "      <td>3</td>\n",
       "      <td>254.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>59.00</td>\n",
       "      <td>2</td>\n",
       "      <td>176.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>54.00</td>\n",
       "      <td>0</td>\n",
       "      <td>239.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.00</td>\n",
       "      <td>0</td>\n",
       "      <td>245.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>54.82</td>\n",
       "      <td>1</td>\n",
       "      <td>177.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>44.00</td>\n",
       "      <td>0</td>\n",
       "      <td>226.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>54.00</td>\n",
       "      <td>0</td>\n",
       "      <td>309.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>67.00</td>\n",
       "      <td>0</td>\n",
       "      <td>237.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>66.00</td>\n",
       "      <td>1</td>\n",
       "      <td>212.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  ca   chol  cp_reduced  exang  fbs  oldpeak  restecg  sex  slope  \\\n",
       "98  41.00   0 250.00           2      0    0     0.00        1    1   2.00   \n",
       "49  69.00   3 254.00           2      0    0     2.00        0    1   1.00   \n",
       "38  59.00   2 176.00           0      0    1     1.08        0    1   1.00   \n",
       "105 54.00   0 239.00           0      0    0     1.20        1    1   2.00   \n",
       "3   63.00   0 245.86           0      1    0     0.00        1    0   1.00   \n",
       "..    ...  ..    ...         ...    ...  ...      ...      ...  ...    ...   \n",
       "50  54.82   1 177.00           0      1    0     0.00        1    1   2.00   \n",
       "154 44.00   0 226.00           2      0    0     0.00        1    1   2.00   \n",
       "75  54.00   0 309.00           1      0    0     1.08        1    1   2.00   \n",
       "28  67.00   0 237.00           0      0    0     1.00        1    1   1.00   \n",
       "219 66.00   1 212.00           0      1    0     0.10        0    1   2.00   \n",
       "\n",
       "     thal  trestbps  \n",
       "98      2       112  \n",
       "49      3       140  \n",
       "38      1       164  \n",
       "105     2       140  \n",
       "3       2       124  \n",
       "..    ...       ...  \n",
       "50      3       140  \n",
       "154     2       120  \n",
       "75      3       108  \n",
       "28      2       120  \n",
       "219     2       112  \n",
       "\n",
       "[193 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>age</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp_reduced</th>\n",
       "      <td>cp_reduced</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column_name  percent_missing\n",
       "age                age             0.00\n",
       "ca                  ca             0.00\n",
       "chol              chol             0.00\n",
       "cp_reduced  cp_reduced             0.00\n",
       "exang            exang             0.00\n",
       "fbs                fbs             0.00\n",
       "oldpeak        oldpeak             0.00\n",
       "restecg        restecg             0.00\n",
       "sex                sex             0.00\n",
       "slope            slope             0.00\n",
       "thal              thal             0.00\n",
       "trestbps      trestbps             0.00"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = x.isnull().sum() * 100 / len(x)\n",
    "missing_value_x = pd.DataFrame({'column_name': x.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                208       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 396\n",
      "Trainable params: 396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 14:47:43.754434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-15 14:47:43.756645: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=(12,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='relu'))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7/7 [==============================] - 1s 44ms/step - loss: 3.1321 - accuracy: 0.4197 - val_loss: 2.3868 - val_accuracy: 0.5510\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.7358 - accuracy: 0.5233 - val_loss: 1.6273 - val_accuracy: 0.5306\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1621 - accuracy: 0.4456 - val_loss: 1.9934 - val_accuracy: 0.4082\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1805 - accuracy: 0.4404 - val_loss: 1.4397 - val_accuracy: 0.5918\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.0149 - accuracy: 0.4456 - val_loss: 2.0046 - val_accuracy: 0.5510\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.9290 - accuracy: 0.4819 - val_loss: 1.3803 - val_accuracy: 0.5306\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.8181 - accuracy: 0.3782 - val_loss: 1.4972 - val_accuracy: 0.4286\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.7370 - accuracy: 0.4041 - val_loss: 1.3132 - val_accuracy: 0.5306\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.5204 - accuracy: 0.4197 - val_loss: 1.2677 - val_accuracy: 0.5306\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.4298 - accuracy: 0.4456 - val_loss: 1.2643 - val_accuracy: 0.4898\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.3913 - accuracy: 0.4352 - val_loss: 1.2149 - val_accuracy: 0.5306\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.3697 - accuracy: 0.4249 - val_loss: 1.1786 - val_accuracy: 0.5306\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.3458 - accuracy: 0.4352 - val_loss: 1.2562 - val_accuracy: 0.5102\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.4077 - accuracy: 0.4352 - val_loss: 1.1285 - val_accuracy: 0.5102\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 1.2966 - accuracy: 0.4197 - val_loss: 1.1365 - val_accuracy: 0.5102\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.3126 - accuracy: 0.3990 - val_loss: 1.1720 - val_accuracy: 0.5102\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 1.2935 - accuracy: 0.4560 - val_loss: 1.0871 - val_accuracy: 0.5306\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.2047 - accuracy: 0.4197 - val_loss: 1.0613 - val_accuracy: 0.5102\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2509 - accuracy: 0.4663 - val_loss: 1.1523 - val_accuracy: 0.5102\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 1.3033 - accuracy: 0.4611 - val_loss: 1.0346 - val_accuracy: 0.5306\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 1.1782 - accuracy: 0.4197 - val_loss: 1.1589 - val_accuracy: 0.5306\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.2481 - accuracy: 0.4508 - val_loss: 1.0131 - val_accuracy: 0.5510\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.2284 - accuracy: 0.5026 - val_loss: 1.1178 - val_accuracy: 0.5102\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.2017 - accuracy: 0.4145 - val_loss: 1.0333 - val_accuracy: 0.5306\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0946 - accuracy: 0.4560 - val_loss: 0.9832 - val_accuracy: 0.5714\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.1249 - accuracy: 0.4663 - val_loss: 1.0313 - val_accuracy: 0.5102\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0805 - accuracy: 0.4611 - val_loss: 0.9668 - val_accuracy: 0.5714\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0667 - accuracy: 0.4301 - val_loss: 1.0108 - val_accuracy: 0.5102\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.1721 - accuracy: 0.4611 - val_loss: 1.0263 - val_accuracy: 0.5306\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.0422 - accuracy: 0.4611 - val_loss: 0.9634 - val_accuracy: 0.5510\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0856 - accuracy: 0.4508 - val_loss: 0.9367 - val_accuracy: 0.5714\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0808 - accuracy: 0.4560 - val_loss: 0.9275 - val_accuracy: 0.5510\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0770 - accuracy: 0.4560 - val_loss: 1.0659 - val_accuracy: 0.5306\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0797 - accuracy: 0.4663 - val_loss: 0.9893 - val_accuracy: 0.5102\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.0873 - accuracy: 0.4663 - val_loss: 0.9298 - val_accuracy: 0.5306\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9897 - accuracy: 0.4249 - val_loss: 0.8935 - val_accuracy: 0.5714\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0146 - accuracy: 0.4767 - val_loss: 0.9457 - val_accuracy: 0.5306\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9761 - accuracy: 0.4663 - val_loss: 0.8800 - val_accuracy: 0.6122\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9594 - accuracy: 0.4663 - val_loss: 0.8736 - val_accuracy: 0.5714\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.9565 - accuracy: 0.4611 - val_loss: 0.8935 - val_accuracy: 0.5510\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 1.0395 - accuracy: 0.4611 - val_loss: 0.8614 - val_accuracy: 0.6122\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9404 - accuracy: 0.4715 - val_loss: 0.8541 - val_accuracy: 0.6122\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9734 - accuracy: 0.4611 - val_loss: 0.8507 - val_accuracy: 0.5918\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0241 - accuracy: 0.4870 - val_loss: 0.9925 - val_accuracy: 0.5510\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9949 - accuracy: 0.4974 - val_loss: 0.8838 - val_accuracy: 0.4898\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0591 - accuracy: 0.4715 - val_loss: 0.8470 - val_accuracy: 0.5306\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9367 - accuracy: 0.4715 - val_loss: 0.8625 - val_accuracy: 0.5510\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9588 - accuracy: 0.5233 - val_loss: 0.8246 - val_accuracy: 0.5918\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9251 - accuracy: 0.4922 - val_loss: 1.0103 - val_accuracy: 0.5510\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9964 - accuracy: 0.5078 - val_loss: 0.8179 - val_accuracy: 0.5918\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9440 - accuracy: 0.4819 - val_loss: 0.8048 - val_accuracy: 0.6122\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9076 - accuracy: 0.4974 - val_loss: 0.8081 - val_accuracy: 0.5918\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0092 - accuracy: 0.4870 - val_loss: 0.8933 - val_accuracy: 0.5510\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.8979 - accuracy: 0.5181 - val_loss: 0.8126 - val_accuracy: 0.5918\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.8680 - accuracy: 0.4922 - val_loss: 0.8353 - val_accuracy: 0.5510\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8917 - accuracy: 0.5130 - val_loss: 0.7884 - val_accuracy: 0.6327\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8493 - accuracy: 0.4922 - val_loss: 0.8051 - val_accuracy: 0.5714\n",
      "Epoch 58/150\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0318 - accuracy: 0.4715 - val_loss: 0.7768 - val_accuracy: 0.6122\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9408 - accuracy: 0.4974 - val_loss: 0.9133 - val_accuracy: 0.5510\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8699 - accuracy: 0.5337 - val_loss: 0.9372 - val_accuracy: 0.5306\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9269 - accuracy: 0.4870 - val_loss: 0.7646 - val_accuracy: 0.6327\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8141 - accuracy: 0.4922 - val_loss: 0.7571 - val_accuracy: 0.6531\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8179 - accuracy: 0.4974 - val_loss: 0.7487 - val_accuracy: 0.6122\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.8775 - accuracy: 0.5130 - val_loss: 0.7697 - val_accuracy: 0.5510\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8152 - accuracy: 0.5181 - val_loss: 0.7784 - val_accuracy: 0.5918\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8379 - accuracy: 0.5078 - val_loss: 0.7432 - val_accuracy: 0.6122\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8598 - accuracy: 0.4974 - val_loss: 0.7343 - val_accuracy: 0.6327\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9547 - accuracy: 0.4870 - val_loss: 0.7820 - val_accuracy: 0.5714\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.5389 - val_loss: 0.7716 - val_accuracy: 0.5714\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8176 - accuracy: 0.5544 - val_loss: 0.8974 - val_accuracy: 0.5510\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8990 - accuracy: 0.5285 - val_loss: 0.7227 - val_accuracy: 0.6122\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7664 - accuracy: 0.4922 - val_loss: 0.7164 - val_accuracy: 0.6531\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.8097 - accuracy: 0.5130 - val_loss: 0.7513 - val_accuracy: 0.5714\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7861 - accuracy: 0.5337 - val_loss: 0.7398 - val_accuracy: 0.5918\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.8130 - accuracy: 0.5492 - val_loss: 0.7069 - val_accuracy: 0.6327\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9103 - accuracy: 0.4611 - val_loss: 0.7978 - val_accuracy: 0.5714\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.8165 - accuracy: 0.5337 - val_loss: 0.7069 - val_accuracy: 0.6327\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7583 - accuracy: 0.5078 - val_loss: 0.7072 - val_accuracy: 0.6327\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7543 - accuracy: 0.5078 - val_loss: 0.7027 - val_accuracy: 0.6327\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7534 - accuracy: 0.5389 - val_loss: 0.7558 - val_accuracy: 0.5918\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8045 - accuracy: 0.4922 - val_loss: 0.6905 - val_accuracy: 0.6327\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.7339 - accuracy: 0.5389 - val_loss: 0.6950 - val_accuracy: 0.6327\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7956 - accuracy: 0.5492 - val_loss: 0.6999 - val_accuracy: 0.5918\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.7601 - accuracy: 0.5181 - val_loss: 0.7416 - val_accuracy: 0.5918\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.7567 - accuracy: 0.5389 - val_loss: 0.6854 - val_accuracy: 0.6327\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.7159 - accuracy: 0.5285 - val_loss: 0.7232 - val_accuracy: 0.6122\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.8846 - accuracy: 0.4922 - val_loss: 0.6763 - val_accuracy: 0.6327\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.8021 - accuracy: 0.5596 - val_loss: 0.8569 - val_accuracy: 0.5102\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7704 - accuracy: 0.5699 - val_loss: 0.6844 - val_accuracy: 0.6327\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7251 - accuracy: 0.5648 - val_loss: 0.7190 - val_accuracy: 0.6122\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7607 - accuracy: 0.5596 - val_loss: 0.6752 - val_accuracy: 0.6939\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8490 - accuracy: 0.5285 - val_loss: 0.7025 - val_accuracy: 0.6327\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.7193 - accuracy: 0.5389 - val_loss: 0.7056 - val_accuracy: 0.6122\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.7079 - accuracy: 0.5803 - val_loss: 0.6882 - val_accuracy: 0.5918\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.7506 - accuracy: 0.5285 - val_loss: 0.6816 - val_accuracy: 0.5918\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9185 - accuracy: 0.5492 - val_loss: 0.7973 - val_accuracy: 0.5102\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7475 - accuracy: 0.5959 - val_loss: 0.7025 - val_accuracy: 0.6327\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7187 - accuracy: 0.5544 - val_loss: 0.6556 - val_accuracy: 0.6735\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.7608 - accuracy: 0.5440 - val_loss: 0.7602 - val_accuracy: 0.5306\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7559 - accuracy: 0.5285 - val_loss: 0.6463 - val_accuracy: 0.6531\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6775 - accuracy: 0.5751 - val_loss: 0.6446 - val_accuracy: 0.6735\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7136 - accuracy: 0.5699 - val_loss: 0.6819 - val_accuracy: 0.6122\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6966 - accuracy: 0.5855 - val_loss: 0.6406 - val_accuracy: 0.6939\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6846 - accuracy: 0.5959 - val_loss: 0.6477 - val_accuracy: 0.6735\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.7422 - accuracy: 0.5285 - val_loss: 0.6397 - val_accuracy: 0.6735\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.7878 - accuracy: 0.5596 - val_loss: 0.8134 - val_accuracy: 0.5306\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.7393 - accuracy: 0.5855 - val_loss: 0.6990 - val_accuracy: 0.5714\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.8546 - accuracy: 0.5130 - val_loss: 0.6640 - val_accuracy: 0.6531\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.7093 - accuracy: 0.5751 - val_loss: 0.7333 - val_accuracy: 0.5102\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.7213 - accuracy: 0.5959 - val_loss: 0.6312 - val_accuracy: 0.6531\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.6734 - accuracy: 0.6218 - val_loss: 0.6418 - val_accuracy: 0.6735\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.6682 - accuracy: 0.6269 - val_loss: 0.6293 - val_accuracy: 0.6531\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6561 - accuracy: 0.6373 - val_loss: 0.6388 - val_accuracy: 0.6735\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 0.6596 - accuracy: 0.6321 - val_loss: 0.6252 - val_accuracy: 0.6735\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.6840 - accuracy: 0.5492 - val_loss: 0.6542 - val_accuracy: 0.6531\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6632 - accuracy: 0.5751 - val_loss: 0.6210 - val_accuracy: 0.6531\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6417 - accuracy: 0.6528 - val_loss: 0.6262 - val_accuracy: 0.6735\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7007 - accuracy: 0.5699 - val_loss: 0.6145 - val_accuracy: 0.7143\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.6800 - accuracy: 0.6114 - val_loss: 0.6149 - val_accuracy: 0.6939\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.8802 - accuracy: 0.4819 - val_loss: 0.7030 - val_accuracy: 0.5714\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7176 - accuracy: 0.6010 - val_loss: 0.8213 - val_accuracy: 0.5714\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7208 - accuracy: 0.5907 - val_loss: 0.6281 - val_accuracy: 0.6735\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.6473 - accuracy: 0.6010 - val_loss: 0.6246 - val_accuracy: 0.6735\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.6428 - accuracy: 0.6477 - val_loss: 0.6177 - val_accuracy: 0.6735\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.6787 - accuracy: 0.5648 - val_loss: 0.6174 - val_accuracy: 0.6735\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.6589 - accuracy: 0.6062 - val_loss: 0.7073 - val_accuracy: 0.5102\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.6530 - accuracy: 0.6166 - val_loss: 0.6233 - val_accuracy: 0.6735\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6389 - accuracy: 0.5907 - val_loss: 0.6103 - val_accuracy: 0.6735\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6232 - accuracy: 0.6632 - val_loss: 0.6088 - val_accuracy: 0.6939\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.6327 - accuracy: 0.6425 - val_loss: 0.6081 - val_accuracy: 0.6939\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.6790 - accuracy: 0.5855 - val_loss: 0.6798 - val_accuracy: 0.6122\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.6818 - accuracy: 0.5648 - val_loss: 0.6260 - val_accuracy: 0.6531\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6890 - accuracy: 0.5907 - val_loss: 0.6268 - val_accuracy: 0.6531\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.6236 - accuracy: 0.6373 - val_loss: 0.6012 - val_accuracy: 0.6939\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.6225 - accuracy: 0.6373 - val_loss: 0.6542 - val_accuracy: 0.5510\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.6548 - accuracy: 0.6166 - val_loss: 0.5983 - val_accuracy: 0.7143\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.6142 - accuracy: 0.6425 - val_loss: 0.5966 - val_accuracy: 0.6939\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.6099 - accuracy: 0.6891 - val_loss: 0.5955 - val_accuracy: 0.6939\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.6153 - accuracy: 0.6632 - val_loss: 0.6286 - val_accuracy: 0.6531\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.6379 - accuracy: 0.5959 - val_loss: 0.5924 - val_accuracy: 0.7143\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.6075 - accuracy: 0.6684 - val_loss: 0.5935 - val_accuracy: 0.7347\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6145 - accuracy: 0.6632 - val_loss: 0.5900 - val_accuracy: 0.7143\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.6431 - accuracy: 0.5959 - val_loss: 0.6183 - val_accuracy: 0.6531\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6159 - accuracy: 0.6632 - val_loss: 0.6147 - val_accuracy: 0.6531\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6223 - accuracy: 0.6580 - val_loss: 0.5857 - val_accuracy: 0.7551\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5928 - accuracy: 0.6943 - val_loss: 0.5995 - val_accuracy: 0.7143\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6405 - accuracy: 0.6062 - val_loss: 0.5817 - val_accuracy: 0.7755\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6783 - accuracy: 0.5855 - val_loss: 0.6946 - val_accuracy: 0.5510\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6570 - accuracy: 0.6580 - val_loss: 0.5821 - val_accuracy: 0.6939\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5946 - accuracy: 0.6839 - val_loss: 0.5777 - val_accuracy: 0.7347\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "history = model.fit(x_train, y_train, batch_size,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy on validation: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a4Um_o5blVGx",
    "Ih5D0w0WlVGy",
    "vLl5KluIlVGy",
    "LY1HXxl3lVG5",
    "QtmDTZWUlVG6",
    "zbGOiPEglVG8",
    "1b07tI86lVG_",
    "a6BCMtZElVHA",
    "HfvgdyEilVHB",
    "s7un-crLlVHD",
    "oy9yh-uEiiXr"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "176px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
