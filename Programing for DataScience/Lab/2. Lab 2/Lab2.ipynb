{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46896a80",
   "metadata": {},
   "source": [
    "# Lab 2: Numpy\n",
    "\n",
    "*Since this is Numpy exercise, you are not allowed to use loop and I will tell you which part you can*\n",
    "\n",
    "(Last update: 07/11/2022)\n",
    "\n",
    "\n",
    "\n",
    "Name: Lê Nguyễn Bình Nam\n",
    "\n",
    "Student code: 20127567"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98060f23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155aa0df",
   "metadata": {},
   "source": [
    "## Instructions for doing and submitting assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181e2a2",
   "metadata": {},
   "source": [
    "&#9889; Note that I will use a software for grading your assignment so you have to follow exactly what I said. If you are not sure about something, please raise your question on Zalo group.\n",
    "\n",
    "**How to do your assignment**\n",
    "\n",
    "You will do your assignment directly on this notebook file. First, you fill your name and student code at the beginning of the file. In this file, you will write your code when you see the following lines of code:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "For optional coding parts, there will be:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "\n",
    "For markdown cell, there will be:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "Of course, you have to remove the `raise NotImplementedError()` statement when you finish.\n",
    "\n",
    "For coding parts, there are often cells below to help you check your answers. You will pass the test if there are no errors when you run the test cells. In some cases, the tests are insufficient. That means that if you do not pass the test, your answer is definitely wrong somewhere, but if you pass the test, your answer may still be incorrect.\n",
    " \n",
    "While doing the assignment, you should print out the output and create more cells for testing. But you have to remove all of them (comment your print-out codes, delete the cell created by you) when you submit your code. <font color=red>Do not remove or edit my cells</font> (except for the aforementioned cells).\n",
    "\n",
    "Keep your code clean and clear by using meaningful variable names and comments, not write too-long coding lines.\n",
    "Press `Ctrl + S` right after editing.\n",
    "\n",
    "Keep it real: The reason why you are here is to <font color=green>study, really study</font>. I highly recommend that you discuss your idea with your friends and <font color=green>write your own code based on your own knowledge</font>. <font color=red>Copy means zero.</font>\n",
    "\n",
    "**How to submit your assignment**\n",
    "\n",
    "When grading your assignment, first, I will choose `Kernel` - `Restart & Run All` in order to restart the kernel and run all cells in your notebook. Therefore, you should do that before submitting to ensure that the outputs are all as expected.\n",
    "\n",
    "After that, you make a submited direction as follow:\n",
    "- Folder `Student code` (for example, if your student code is 1234567, then you name your folder `1234567`)\n",
    "    - File `Lab2.ipynb` only\n",
    "\n",
    "Finally, you compress your folder (`Student code`) and submit on Moodle. <font color=red>Please strictly follow the submission rules.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ce040",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5861b79",
   "metadata": {},
   "source": [
    "## Programming environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dd304",
   "metadata": {},
   "source": [
    "- You will re-use the Linux environment setup in Lab 0 - WarmUp. Don't forget to start your coding environment (`conda activate min_ds-env`) before doing your assignment.\n",
    "- Use Jupyter notebook or Jupyter lab, <font color=red>not Google Colab</font> (I can not grade you well on Google Colab) to edit your `*.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d0ddac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/miniconda3/envs/min_ds-env/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed058f",
   "metadata": {},
   "source": [
    "Your file now should run on `min_ds-env`.\n",
    "\n",
    "You will not use `pandas` here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61e06a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1372718",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2cfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb29f77",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6098d27a",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ae3ae",
   "metadata": {},
   "source": [
    "In this assignment, we simply use a collected dataset. You can download it [here](https://files.grouplens.org/datasets/movielens/ml-100k/u.data) and save the file as \"u.data\" (not \"u.txt\" or anything else). The dataset has more than one file but you just have to use a single file named \"u.data\".\n",
    "\n",
    "According to the [data description file](https://files.grouplens.org/datasets/movielens/ml-100k-README.txt):\n",
    "> MovieLens data sets were collected by the GroupLens Research Project\n",
    "at the University of Minnesota.\n",
    "> \n",
    "> This data set consists of:\n",
    "> * 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "> * Each user has rated at least 20 movies.  \n",
    "> * Simple demographic info for the users (age, gender, occupation, zip)\n",
    ">\n",
    "> The data was collected through the MovieLens web site\n",
    "(movielens.umn.edu) during the seven-month period from September 19th, \n",
    "1997 through April 22nd, 1998. This data has been cleaned up - users\n",
    "who had less than 20 ratings or did not have complete demographic\n",
    "information were removed from this data set. Detailed descriptions of\n",
    "the data file can be found at the end of this file.\n",
    "\n",
    "The above is the general description of all file in dataset. The description of \"u.data\" is in the following:\n",
    "> The full u data set, 100000 ratings by 943 users on 1682 items. Each user has rated at least 20 movies. Users and items are numbered consecutively from 1. The data is randomly ordered. This is a tab separated list of user id | item id | rating | timestamp. The time stamps are unix seconds since 1/1/1970 UTC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a99fa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804be566",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4673a3c",
   "metadata": {},
   "source": [
    "<!-- ### Dữ liệu có bao nhiêu dòng và bao nhiêu cột? (0.5đ) -->\n",
    "### How many rows and columns in dataset? (0.5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41593a06",
   "metadata": {},
   "source": [
    "First of all, you have to read the file \"u.data\" into a numpy array named `raw_ratings` (use function `np.genfromtxt`). Let `dtype` be `np.uint64`. You also have to put \"u.data\" in the same directory with this notebook file so you can just pass \"u.data\" to the function.\n",
    "\n",
    "Next, you calculate the number of rows and columns and save them into `n_rows` and `n_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9013cf72",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "969205f46fed7422d8972495c4c36348",
     "grade": false,
     "grade_id": "cell-1bf7d4be2f1eb278",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "dataset_path = './u.data'\n",
    "raw_ratings = np.genfromtxt(dataset_path,\n",
    "                        delimiter=\"\\t\",\n",
    "                        dtype=np.uint64)\n",
    "\n",
    "n_rows = raw_ratings.shape[0]\n",
    "n_cols = raw_ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2871f983",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71ee63014fe20f7ca0d15826e9578442",
     "grade": true,
     "grade_id": "cell-fd69b593a2722fbc",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      196,       242,         3, 881250949],\n",
       "       [      186,       302,         3, 891717742],\n",
       "       [       22,       377,         1, 878887116],\n",
       "       [      244,        51,         2, 880606923],\n",
       "       [      166,       346,         1, 886397596]], dtype=uint64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "assert raw_ratings.dtype == np.uint64\n",
    "assert raw_ratings.ndim == 2\n",
    "assert n_rows == 100000\n",
    "assert n_cols == 4\n",
    "raw_ratings[:5] # Xem 5 dòng đầu tiên"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d440322",
   "metadata": {},
   "source": [
    "### What is the meaning of each row? Are there any 2 rows with different meaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec1df2",
   "metadata": {},
   "source": [
    "According to data description file and by taking a quick look at the data, each line provides information about the score that a user rates a movie. It seems that there is no outlier line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3b9ac",
   "metadata": {},
   "source": [
    "<!-- ### Dữ liệu có các dòng bị lặp không? (0.5đ) -->\n",
    "### Is the data duplicated? (0.5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a8254",
   "metadata": {},
   "source": [
    "<!-- Bạn sẽ kiểm tra vụ này và lưu kết quả vào biến `have_duplicated_rows`. Biến này sẽ có giá trị True nếu dữ liệu có các dòng bị lặp và có giá trị False nếu ngược. -->\n",
    "You are going to check that and save the result into `have_duplicated_rows`. The value of this variable is `True` if the data is not duplicated and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138597cc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fadc1b859d04ad7d4bd45451142794bf",
     "grade": false,
     "grade_id": "cell-c184a3a04425a1c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "have_duplicated_rows = len(raw_ratings) != len(np.unique(raw_ratings, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372202fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17161cf45b9f0757fd42c2040a5b025b",
     "grade": true,
     "grade_id": "cell-7f2d2f011cc33f7d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert have_duplicated_rows == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019928b",
   "metadata": {},
   "source": [
    "<!-- ### Mỗi cột có ý nghĩa gì? -->\n",
    "### What is the meaning of each row?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0466dc8",
   "metadata": {},
   "source": [
    "According to the data description file:\n",
    "- Col #1: The ID of the user who participated in the rating\n",
    "- Col #2: The ID of the movie\n",
    "- Col #3: The score that user rated\n",
    "- Col #4: The time when user did the rating (in second, count from 1/1/1970 UCT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a41a1",
   "metadata": {},
   "source": [
    "<!-- ### Mỗi cột hiện đang có kiểu dữ liệu gì? Có cột nào có kiểu dữ liệu chưa phù hợp để có thể xử lý tiếp không? -->\n",
    "\n",
    "### What is the datatype of each column? Are there any columns with datatype that is not suitable for further processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a7de37",
   "metadata": {},
   "source": [
    "<!-- Hiện tại thì tất cả các cột đều có kiểu dữ liệu là số: -->\n",
    "The datatypes of all columns are all numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f0a76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ratings.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a48a4",
   "metadata": {},
   "source": [
    "All the columns have the suitable datatype.\n",
    "\n",
    "You might think that the the datatype of the final column is not suitable? In fact, this column represents dates in the form of number. We still can find min/max values and can convert them to datetime format when needed. The point is that you can not store 2 different datatypes in the same numpy array. Therefore, if you change the datatype of that column, you have to prepare another numpy array to store these datetime values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651709d",
   "metadata": {},
   "source": [
    "<!-- ### Với mỗi cột có kiểu dữ liệu dạng số (numeric) và dạng datetime, các giá trị được phân bố như thế nào? (1đ) -->\n",
    "### How does the numeric/datetime data distribute? (1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e765ae8",
   "metadata": {},
   "source": [
    "It looks like that the datatype of columns are numeric. But you might notice that the datatype of \"user id\" column and \"movie id\" column should be catergorical. According to this approach, there will be 2 numeric columns (\"rating\" and \"timestamp\").\n",
    "\n",
    "How many missing values do these two columns have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f7a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(raw_ratings[:, 2:]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29f8b8",
   "metadata": {},
   "source": [
    "What you are going to do next is to find the min, median, max values of these 2 numeric columns (use function `np.percentile`, let the `interpolation` option be `linear`). Then, save the result into 2 variables named `rate_col_profile` and `rate_date_col_profile`. These are 2 1d numpy arrays. The datatype of `rate_col_profile` is real number and the one of `rate_date_col_profile` is `datetime64[s]`\n",
    "\n",
    "Hint: When converting an array, you can pass the datatype in the form of string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806a51aa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ac19dfa727037d4ac37c1066a002523",
     "grade": false,
     "grade_id": "cell-15364ea0e0e9c792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "numeric_ratings = raw_ratings[:, 2]\n",
    "datetime_ratings = raw_ratings[:, -1].astype('datetime64[s]')\n",
    "\n",
    "rate_col_profile = []\n",
    "rate_col_profile.append(float(np.min(numeric_ratings)))\n",
    "rate_col_profile.append(np.percentile(numeric_ratings, 50))\n",
    "rate_col_profile.append(float(np.max(numeric_ratings)))\n",
    "\n",
    "rate_date_col_profile = []\n",
    "rate_date_col_profile.append(np.min(datetime_ratings))\n",
    "rate_date_col_profile.append(np.percentile(datetime_ratings, 50))\n",
    "rate_date_col_profile.append(np.max(datetime_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225c0b82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78d180caf83dcc88a508b4a90424e189",
     "grade": true,
     "grade_id": "cell-3f3b0054dd6eadb9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert np.array_equal(rate_col_profile, np.array([1., 4., 5.]))\n",
    "assert np.array_equal(rate_date_col_profile, \n",
    "                      np.array(['1997-09-20T03:05:10', \n",
    "                                '1997-12-22T21:42:24',\n",
    "                                '1998-04-22T23:10:38'], \n",
    "                               dtype='datetime64[s]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeedcf8",
   "metadata": {},
   "source": [
    "Min value and max value of these columns are normal and match the information in data description file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7a821",
   "metadata": {},
   "source": [
    "<!-- ### Với mỗi cột có kiểu dữ liệu dạng phân loại (categorical), các giá trị được phân bố như thế nào? (1đ) -->\n",
    "### How does the catergorical data distribute? (1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd939f3",
   "metadata": {},
   "source": [
    "As aforementioned, the 2 first columns contain categorical data.\n",
    "\n",
    "How many missing values do these two columns have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e22e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(raw_ratings[:, :2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935345c",
   "metadata": {},
   "source": [
    "Now, for each column, you have to find out 5 values: number of different values; least occurrence value and number of occurrences (2 values); most occurrence value and number of occurrences (2 values); Save these list into `user_col_profile` and `movie_col_profile`.\n",
    "\n",
    "Note: If there are more than one value with the least/most occurrence, just take the smallest/biggest value (hint: if you let `kind=stable` in sort function, Numpy will ensure that the order of the same values in the original array does not change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb24a3b2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b2f1821e4825d46cbba96dc7b80c5b6",
     "grade": false,
     "grade_id": "cell-09819763bd956c3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "user = raw_ratings[:, 0].astype(np.int64)\n",
    "num_users = len(np.unique(user))\n",
    "\n",
    "counts = np.bincount(user)\n",
    "min_value = min(counts[1:])\n",
    "id_min = np.where(counts == min_value)[0]\n",
    "id_min = id_min[0]\n",
    "max_value = max(counts[1:])\n",
    "id_max = np.where(counts == max_value)[0]\n",
    "id_max = id_max[0]\n",
    "\n",
    "user_col_profile = [num_users, id_min, min_value, id_max, max_value]\n",
    "\n",
    "movie = raw_ratings[:, 1].astype(np.int64)\n",
    "num_movies = len(np.unique(movie))\n",
    "\n",
    "counts = np.bincount(movie)\n",
    "\n",
    "min_value = min(counts[1:])\n",
    "id_min = np.where(counts == min_value)[0]\n",
    "id_min = id_min[0]\n",
    "\n",
    "max_value = max(counts[1:])\n",
    "id_max = np.where(counts == max_value)[0]\n",
    "id_max = id_max[0]\n",
    "movie_col_profile = [num_movies, id_min, min_value, id_max, max_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c49bef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2d87e103900fd26d436366c138e3937",
     "grade": true,
     "grade_id": "cell-9f4bbdb1bcb99063",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert user_col_profile==[943, # Có chừng này user\n",
    "                          19,  # Đây là user rate ít movie nhất\n",
    "                          20,  # và đó là chừng này movie\n",
    "                          405, # Đây là user rate nhiều movie nhất\n",
    "                          737] # và đó là chừng này movie\n",
    "assert movie_col_profile==[1682,#Có chừng này movie\n",
    "                           599, #Đây là movie được ít user rate nhất\n",
    "                           1,   #và đó là chừng này user\n",
    "                           50,  #Đây là movie được nhiều user rate nhất\n",
    "                           583] #và đó là chừng này user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee0678",
   "metadata": {},
   "source": [
    "These informations match the information in the data description file:\n",
    "> The full u data set, 100000 ratings by 943 users on 1682 items. Each user has rated at least 20 movies. Users and items are numbered consecutively from 1.\n",
    "\n",
    "The state \"Users and items are numbered consecutively from 1\" is not varified. You can check that by running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1586c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User id  - min & max: 1 & 943\n",
      "Movie id - min & max: 1 & 1682\n"
     ]
    }
   ],
   "source": [
    "print('User id  - min & max:', \n",
    "      raw_ratings[:, 0].min(), '&', raw_ratings[:, 0].max()) \n",
    "print('Movie id - min & max:', \n",
    "      raw_ratings[:, 1].min(), '&', raw_ratings[:, 1].max()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb7d84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20a067",
   "metadata": {},
   "source": [
    "## Propose meaningful questions & Answer them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb99848",
   "metadata": {},
   "source": [
    "After exploration process, you already have a deeper understanding about the data. For now, you will propose meaningful questions that can answer by using the data. \n",
    "\n",
    "They could be: \\\n",
    "*Which movies should we recommend for each user?*\n",
    "\n",
    "<!-- Việc tìm ra câu trả lời cho câu hỏi này sẽ giúp ích cho cả người dùng và nhà cung cấp dịch vụ xem phim: -->\n",
    "All users and film providers will benefit a lot after answering this question:\n",
    "\n",
    "<!-- - Người dùng: người dùng có thể muốn xem phim, nhưng có rất nhiều phim và người dùng không biết nên xem phim nào; sẽ rất tiện cho người dùng nếu hệ thống có thể đề xuất một danh sách phim mà nhiều khả năng người dùng sẽ thích -->\n",
    "- Users: There are a lot of movies and users might not know which movies to choose. It is so great if your system can provide a list of movies that users may love them.\n",
    "<!-- - Nhà cung cấp dịch vụ xem phim: nếu hệ thống đề xuất tốt thì nhiều khả năng người dùng sẽ xem phim và sẽ thích, nghĩa là người dùng sẽ tiếp tục trả phí để sử dụng dịch vụ ;-) -->\n",
    "- Film provider: If your system work well, users will keep using your service and pay more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d3d6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3413be",
   "metadata": {},
   "source": [
    "## Pre-processing (1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d5f29",
   "metadata": {},
   "source": [
    "<!-- Việc xây dựng hệ thống đề xuất sản phẩm mình đã có nói sơ bộ ở buổi học 09. Đầu tiên, từ dữ liệu ban đầu là array `raw_ratings`, bạn sẽ cần tạo array `ratings` gồm số-lượng-user dòng và số-lượng-movie cột, `ratings[i, j]` cho biết user có id i đã cho movie có id j bao nhiêu điểm, nếu chưa cho thì giá trị sẽ là `nan`. Vì Python đánh chỉ số từ 0 nên bạn cũng cần chỉnh lại để id của user và movie bắt đầu từ 0 (thay vì 1). -->\n",
    "\n",
    "First, you have to create array `ratings` from `raw_ratings`. `ratings` is a 2d numpy array. `rattings[i,j]` represents the score that user i graded movie j. If user i does not grade movie j, then `ratings[i,j]=nan`.\n",
    "\n",
    "Note: The index should start from 0. That means user 1 in `ratings` will be represented by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512671b3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ce14ac032aded94c7d9d391ec305fc0",
     "grade": false,
     "grade_id": "cell-11ff284c3fe7fb7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "user = raw_ratings[:,0] - 1\n",
    "movie = raw_ratings[:,1] - 1\n",
    "\n",
    "row = np.unique(user).size\n",
    "col = np.unique(movie).size\n",
    "\n",
    "ratings = np.zeros((row, col))\n",
    "\n",
    "ratings[user, movie] = raw_ratings[:, 2]\n",
    "ratings[ratings == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65cc1d91",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "129b541ee545b7ad80ef9187b0ac5c05",
     "grade": true,
     "grade_id": "cell-fb18066caaa407ed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ratings.shape == (943, 1682)\n",
    "missing_ratios = np.mean(np.isnan(ratings))\n",
    "assert missing_ratios.round(3) == 0.937 # Có 93.7% giá trị nan!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c2a40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071c835",
   "metadata": {},
   "source": [
    "## Analyze data to answer the question (6p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653cfcd",
   "metadata": {},
   "source": [
    "<!-- Để có thể đề xuất các movie cho mỗi user thì ta sẽ phải làm 2 công đoạn: -->\n",
    "In order for your system to recommend movies, you have to do 2 steps:\n",
    "\n",
    "- Step #1: Predict the score that a user grade an unseen movie. In the other words, you have to fill in the nan values in array `ratings`.\n",
    "\n",
    "- Step #2: Recommend unseen movies that have high score for user.\n",
    "\n",
    "In this assignment, we only forcus on step #1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b0b1f",
   "metadata": {},
   "source": [
    "I have uploaded some materials that can help you learn how to use NumPy better as well as how to predict movie scores for a user. In this assignment, you will predict the scores for all users. Note that you are not allowed to use loops (for, while) since this is the lab about Numpy. Therefore, instead of doing that, you will predict the scores for all users at the same time. In order for you to do that, you will have to predict the score that a user will give not just a movie but all movies (even movies that he or  she has already watched). Calculating scores for movies that he/she watched is not necessary, but it will help your calculation process speed up (because we calculate for all users at the same time).\n",
    "\n",
    "In fact, you can't process all users at the same time because of a lack of memory (the temporary arrays generated in the computing process will have the size of `#users * #users * #movies`). In order to solve that problem, you can divide your data into batches (a group of users) so the temporary arrays will only have the size of `batch_size * #users * #movies`. When you successfully calculate the scores for a batch of users, you can use loops (for, while) to calculate the scores for all users by traversing all batches.\n",
    "\n",
    "Let `batch_size=32`, you will have to fill the array `filled_ratings` with the scores of all movies. When doing your homework, **you should not change the `ratings` array**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4fde3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "filled_ratings = np.empty_like(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c80f1",
   "metadata": {},
   "source": [
    "I do not mean to scare you, but the implementation is quite complex and mainly based on **broadcasting mechanism**. Therefore, first, you should try predicting the score on a batch. I will help you on that by dividing it into steps and providing test suits for each of them. The important point is that somehow, you change from predicting scores for a user to predicting scores for a batch of users: there will be a dimension at the beginning of the array corresponding to the size of `batch_size`.\n",
    "\n",
    "First, you will predict the scores for a batch of users indexing from `start` to `end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e32c62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ea6f4",
   "metadata": {},
   "source": [
    "**Step #1**: Calculate `similarities` array that shows the similarity between each client in the batch under consideration and all uses. The size of this array will be `batch_size * #users`. `similarities[i,j]` represents the similarity level of user i (in the batch) and user j (in all users). If there are 2 users that do not overlap any movies, there will be a warning that says \"RuntimeWarning: Mean of empty slice.\" In this case, just let the similarity be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a219bc83",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f04fe3d37e91f17cbf7058aed71d0a82",
     "grade": false,
     "grade_id": "cell-1d34779ee4335381",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_859/147193662.py:3: RuntimeWarning: Mean of empty slice\n",
      "  similarities = np.nanmean(np.abs(np.expand_dims(ratings, 0) - np.expand_dims(first_batch, 1)), axis=2)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "first_batch = ratings[start:end]\n",
    "similarities = np.nanmean(np.abs(np.expand_dims(ratings, 0) - np.expand_dims(first_batch, 1)), axis=2)\n",
    "similarities = 1 / (similarities + 0.001)\n",
    "similarities[np.isnan(similarities)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bab1c41c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c33d00765e83dd568159477781da990e",
     "grade": true,
     "grade_id": "cell-3c3f855070577541",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert similarities.shape == (32, 943)\n",
    "assert np.array_equal(similarities[:3, :3].round(1), \n",
    "                      np.array([[1.0e+03, 1.1e+00, 7.0e-01],\n",
    "                                [1.1e+00, 1.0e+03, 7.0e-01],\n",
    "                                [7.0e-01, 7.0e-01, 1.0e+03]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ece864",
   "metadata": {},
   "source": [
    "**Step #2**: Compute the array \"weights\" as a normalized version of array \"similarity\". For each user in the batch, the similarity with all other users will be normalized for each movie: normalize for users who have given movie scores by dividing the similarity by the total similarity that only considers users who have given movie scores, with the rest of the users normalizing by giving similarity zero. The array \"weights\" will have dimensions of `batch_size * #users * n_movies`. When running, you will see a warning: `RuntimeWarning: invalid value encountered in true_divide.` This is because the users that rate the movie have a similarity of 0 for all users, resulting in a normalization of 0/0 and nan as a result. In this case, it means that there is not enough information to predict the score, and for this lesson, you will leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4947f7c0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da01da876e8b56c6432d791f73618a6b",
     "grade": false,
     "grade_id": "cell-3d0537bb94c333e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_859/3578830350.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = a / np.expand_dims(np.sum(a, axis=1), 1)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "a =  ~np.isnan(np.expand_dims(ratings, 0)) * np.expand_dims(similarities, 2) \n",
    "weights = a / np.expand_dims(np.sum(a, axis=1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52c573fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 943, 1682)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01823615",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ed0ec51e4cad533809106c7ff74caa8",
     "grade": true,
     "grade_id": "cell-04b8a47e95e8dd09",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert weights.shape == (32, 943, 1682)\n",
    "assert np.sum(np.isnan(weights)) == 31119"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c6af9",
   "metadata": {},
   "source": [
    "**Step 3**: For each user in the batch, calculate scores (for all the moves) by multiplying the score of that user by the corresponding weight in `weight` array. Then, store the result into a line of the array `filled_ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d9e8bb9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8736ae9cc0826cdae3a22e8f8406b045",
     "grade": false,
     "grade_id": "cell-e73c0a38ffa925db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "filled_ratings = np.nansum(weights * ratings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bde0f216",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72ece520b84bb40fe8012711ca6a064c",
     "grade": true,
     "grade_id": "cell-9a094032ccb1726a",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "filled_batch = filled_ratings[start:end]\n",
    "filled_nanvals = filled_batch[np.isnan(ratings[start:end])]\n",
    "assert np.array_equal(filled_nanvals[:3].round(1),\n",
    "                      np.array([3.6, 3.5, 4. ]))\n",
    "assert np.array_equal(filled_nanvals[-3:].round(1),\n",
    "                      np.array([2., 3., 3. ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eebe8c",
   "metadata": {},
   "source": [
    "For now, you can run on all the data (0.5p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9ed9adb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa8de9927513fd4a907f496d0ec51de6",
     "grade": false,
     "grade_id": "cell-9ee6c3bd8e2dea97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_859/346904947.py:4: RuntimeWarning: Mean of empty slice\n",
      "  similarities = np.nanmean(np.abs(np.expand_dims(ratings, 0) - np.expand_dims(batch, 1)), axis=2)\n",
      "/tmp/ipykernel_859/346904947.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = weights / np.expand_dims(np.sum(weights, axis=1), 1)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def predict(start):\n",
    "    batch = ratings[start:start + batch_size]\n",
    "    similarities = np.nanmean(np.abs(np.expand_dims(ratings, 0) - np.expand_dims(batch, 1)), axis=2)\n",
    "    similarities = 1 / (similarities + 0.001)\n",
    "    similarities[np.isnan(similarities)] = 0.0\n",
    "    \n",
    "    weights = ~np.isnan(np.expand_dims(ratings, 0)) * np.expand_dims(similarities, 2)\n",
    "    weights = weights / np.expand_dims(np.sum(weights, axis=1), 1)\n",
    "    \n",
    "    return np.nansum(weights * ratings, axis=1)\n",
    "\n",
    "filled_ratings = np.empty_like(ratings)\n",
    "for start in range(0, ratings.shape[0], batch_size):\n",
    "    filled_ratings[start:start + batch_size,:] = predict(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8600265",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c1cef3424f92b66a41ca49dd440f262",
     "grade": true,
     "grade_id": "cell-5e6aaf23d47e5193",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "filled_nanvals = filled_ratings[np.isnan(ratings)]\n",
    "assert np.array_equal(filled_nanvals[:3].round(1),\n",
    "                      np.array([3.6, 3.5, 4. ]))\n",
    "assert np.array_equal(filled_nanvals[-3:].round(1),\n",
    "                      np.array([0., 3., 3. ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
